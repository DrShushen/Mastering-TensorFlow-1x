{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92616a8-dded-41bd-ac9b-3b00dc604039",
   "metadata": {},
   "source": [
    "# Sonnet\n",
    "<img src=\"https://camo.githubusercontent.com/60d40f8702f33a7f7427aec58ff28001668f51767b33032f959265a0b8ab6382/68747470733a2f2f736f6e6e65742e6465762f696d616765732f736f6e6e65745f6c6f676f2e706e67\" width=300/>\n",
    "\n",
    "### URLs:\n",
    "* GitHub: https://github.com/deepmind/sonnet\n",
    "* GitHub tags: https://github.com/deepmind/sonnet/tags\n",
    "* PyPI: https://pypi.org/project/dm-sonnet\n",
    "* PyPI release history: https://pypi.org/project/dm-sonnet/#history\n",
    "\n",
    "### Installation:\n",
    "**Note:** ⚠️ Latest version compatible with TF1 (as of 2021-07) is `v1.36`.\n",
    "```bash\n",
    "pip install 'dm-sonnet==1.36'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73746544-351e-4395-9fd1-0a24db792996",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Sonnet is an **object-oriented** library written in Python. It was released by DeepMind in 2017. \n",
    "\n",
    "Sonnet intends to cleanly separate the following two aspects of building computation graphs from objects:\n",
    "* The configuration of objects called modules\n",
    "* The connection of objects to computation graphs\n",
    "\n",
    "The modules are defined as sub-classes of the abstract class `sonnet.AbstractModule`. \n",
    "At the time of writing this book, the following modules are available in Sonnet:\n",
    "\n",
    "* **Basic modules:** `AddBias`, `BatchApply`, `BatchFlatten`, `BatchReshape`, `FlattenTrailingDimensions`, `Linear`, `MergeDims`, `SelectInput`, `SliceByDim`, `TileByDim`, `TrainableVariable`\n",
    "* **Recurrent modules:** `DeepRNN`, `ModelRNN`, `VanillaRNN`, `BatchNormLSTM`, `GRU`, and `LSTM`\n",
    "* **Recurrent + ConvNet modules:** `Conv1DLSTM` and `Conv2DLSTM`\n",
    "* **ConvNet modules:** `Conv1D`, `Conv2D`, `Conv3D`, `Conv1DTranspose`, `Conv2DTranspose`, `Conv3DTranspose`, `DepthWiseConv2D`, `InPlaneConv2D`, and `SeparableConv2D`\n",
    "* **ResidualNets:** `Residual`, `ResidualCore`, and `SkipConnectionCore`\n",
    "* **Others:** `BatchNorm`, `LayerNorm`, `clip_gradient`, and `scale_gradient`\n",
    "\n",
    "We can define our own new modules by creating a sub-class of `sonnet.AbstractModule.\n",
    "\n",
    "### Sonnet Workflow\n",
    "1. Create classes for the dataset and network architecture which inherit from `sonnet.AbstractModule`. In our example, we create an `MNIST` class and an `MLP` class.\n",
    "2. Define the parameters and hyperparameters.\n",
    "3. Define the test and train datasets from the dataset classes defined in the preceding step.\n",
    "4. Define the model using the network class defined. As an example, `model = MLP([20, n_classes])` in our case creates an MLP network with two layers of 20 and the `n_classes` number of neurons each.\n",
    "5. Define the `y_hat` placeholders for the train and test sets using the model.\n",
    "6. Define the loss placeholders for the train and test sets.\n",
    "7. Define the optimizer using the train loss placeholder.\n",
    "8. Execute the loss function in a TensorFlow session for the desired number of epochs to optimize the parameters.\n",
    "\n",
    "### Final Note:\n",
    "This library is vaguely reminiscent of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80d7d64-c35f-405f-8ffe-015ede2deb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa36fcd-a39a-49cd-9047-89326fb16970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sonnet as snt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56afc216-1c05-4ac6-a3d9-76aaf1b40930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf24681-9391-4447-b060-dc4f826c62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb785de-2b3d-46c3-b1aa-c517f42715b8",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "`tf.gather()`\n",
    "> Gather slices from params axis axis according to indices. indices must be an integer tensor of any dimension (usually 0-D or 1-D).\n",
    "\n",
    "```python\n",
    "tf.gather(\n",
    "    params, indices, validate_indices=None, name=None, axis=None, batch_dims=0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fd5dc2-dfac-47e0-81cc-4193cc17c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MNIST class (Inherits from snt.AbstractModule!)\n",
    "class MNIST(snt.AbstractModule):\n",
    "\n",
    "    def __init__(self, mnist_part, batch_size, name='MNIST'):\n",
    "\n",
    "        super(MNIST, self).__init__(name=name)\n",
    "\n",
    "        self._X = tf.constant(mnist_part.images, dtype=tf.float32)\n",
    "        self._Y = tf.constant(mnist_part.labels, dtype=tf.float32)\n",
    "        self._batch_size = batch_size\n",
    "        self._M = mnist_part.num_examples\n",
    "\n",
    "    def _build(self):\n",
    "        idx = tf.random_uniform([self._batch_size], 0, self._M, tf.int64)\n",
    "        X = tf.gather(self._X, idx)  # See: https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/gather\n",
    "        Y = tf.gather(self._Y, idx)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa1926c-282e-4fce-a37a-8e7d65d63239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP class (Inherits from snt.AbstractModule!)\n",
    "class MLP(snt.AbstractModule):\n",
    "    def __init__(self, output_sizes, name='mlp'):\n",
    "        super(MLP, self).__init__(name=name)\n",
    "\n",
    "        self._layers = []\n",
    "\n",
    "        for output_size in output_sizes:\n",
    "            self._layers.append(snt.Linear(output_size=output_size))\n",
    "\n",
    "    def _build(self, X):\n",
    "\n",
    "        # add the input layer\n",
    "        model = tf.sigmoid(self._layers[0](X))\n",
    "\n",
    "        # add hidden layers\n",
    "        for i in range(1, len(self._layers) - 1):\n",
    "            model = tf.sigmoid(self._layers[i](model))\n",
    "\n",
    "        # add output layer\n",
    "        model = tf.nn.softmax(self._layers[len(self._layers) - 1](model))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "733b069f-50a9-4107-8254-6d2d47bf87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_classes = 10\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9ef60c-ddbb-4a1e-b483-87c69bfc1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a742abbbcef1>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\n",
    "    os.path.join('.', 'mnist'),\n",
    "    one_hot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394e2c94-47c0-45fe-be6e-1a52f092ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(mnist.train, batch_size=batch_size)\n",
    "test = MNIST(mnist.test, batch_size=batch_size)\n",
    "\n",
    "X_train, Y_train = train()\n",
    "X_test, Y_test = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc0012b-4919-480e-a144-17ba8adf2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP([20, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "173e6954-8be3-4240-a038-42cf291ca69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/sonnet/python/modules/basic.py:127: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/sonnet/python/modules/basic.py:132: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Note: **before any training**\n",
    "Y_train_hat = model(X_train)\n",
    "Y_test_hat = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d64993b-31ee-40ee-a734-748acc58b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_hat, Y):\n",
    "    return -tf.reduce_sum(Y * tf.log(Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d8ed4e-30b6-45ee-9b37-3e7a2144d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = loss(Y_train_hat, Y_train)\n",
    "L_test = loss(Y_test_hat, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e6ec9b-82c7-4939-bb8b-848aae9f4dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mlp/Softmax:0\", shape=(100, 10), dtype=float32)\n",
      "Tensor(\"Neg:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_hat)\n",
    "print(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea984a3a-d6cb-48dc-a381-efc175223a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c9e858-823d-4e55-8c58-e435ce0fd60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Training Loss : 236.387939453125\n",
      "Epoch : 1 Training Loss : 229.48268127441406\n",
      "Epoch : 2 Training Loss : 222.2772216796875\n",
      "Epoch : 3 Training Loss : 221.61489868164062\n",
      "Epoch : 4 Training Loss : 219.23606872558594\n",
      "Epoch : 5 Training Loss : 214.39312744140625\n",
      "Epoch : 6 Training Loss : 203.90213012695312\n",
      "Epoch : 7 Training Loss : 197.7329864501953\n",
      "Epoch : 8 Training Loss : 197.83961486816406\n",
      "Epoch : 9 Training Loss : 190.5469970703125\n",
      "Test loss : 185.12721252441406\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as tfs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        loss_val, _ = tfs.run((L_train, optimizer))\n",
    "        print('Epoch : {} Training Loss : {}'.format(epoch, loss_val))\n",
    "\n",
    "    loss_val = tfs.run(L_test)\n",
    "    print('Test loss : {}'.format(loss_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
