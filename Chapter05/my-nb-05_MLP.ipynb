{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45076b4b-cfe6-4b84-bc1b-c4389cb008f2",
   "metadata": {},
   "source": [
    "# Overview Notes\n",
    "\n",
    "In this chapter, we are going to further expand on the following topics:\n",
    "* The perceptron (artificial neuron)\n",
    "* Feed forward neural networks\n",
    "* **MultiLayer Perceptron (MLP)** for *image classification*\n",
    "    * `TensorFlow`-based MLP for MNIST image classification\n",
    "    * `Keras`-based MLP for MNIST classification\n",
    "    * `TFLearn`-based MLP for MNIST classification\n",
    "* MLP for time series regression\n",
    "\n",
    "## Building up an MLP\n",
    "\n",
    "#### 1. Simple perceptron (**Note NO weights, bias, or activation!**):\n",
    "\n",
    "<img src=\"./SimplePerceptron.png\"/>\n",
    "\n",
    "\n",
    "#### 2. Simple perceptron with $W$ and $b$:\n",
    "\n",
    "<img src=\"./SimplePerceptron_W_b.png\"/>\n",
    "\n",
    "\n",
    "#### 3. Simple perceptron with $W$ and $b$ and *activation* $\\varphi(.)$:\n",
    "\n",
    "<img src=\"./SimplePerceptron_W_b_Activation.png\"/>\n",
    "\n",
    "  * $ReLU(x)=\\max(0,x): [0,x]$\n",
    "  * $sigmoid(x)=\\frac{1}{1-e^{-x}}: [0,1]$\n",
    "  * $\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}: [-1,1]$\n",
    "\n",
    "\n",
    "#### 4. This can also be shown as a simplest NN with one neuron:\n",
    "\n",
    "<img src=\"./NN_One_Neuron.png\"/>\n",
    "\n",
    "\n",
    "#### 5. MLP:\n",
    "\n",
    "<img src=\"./MLP.png\"/>\n",
    "\n",
    "* the MLP depicted in the above diagram has three features as inputs: two hidden layers of five neurons each and one output $y$. \n",
    "* The neurons are fully connected to the neurons of the next layer. \n",
    "* Such layers are also called *dense* layers or affine layers and such models are also known as *sequential models*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53dfa9-ab08-49ce-a06b-9a0cf1f1c6dc",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#MNIST-Dataset\" data-toc-modified-id=\"MNIST-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MNIST Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-the-MNIST-data\" data-toc-modified-id=\"Get-the-MNIST-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Get the MNIST data</a></span></li><li><span><a href=\"#MLP-in-TensorFlow\" data-toc-modified-id=\"MLP-in-TensorFlow-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>MLP in TensorFlow</a></span></li><li><span><a href=\"#MLP-in-Keras\" data-toc-modified-id=\"MLP-in-Keras-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>MLP in Keras</a></span></li><li><span><a href=\"#MLP-in-TFLearn\" data-toc-modified-id=\"MLP-in-TFLearn-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>MLP in TFLearn</a></span></li></ul></li><li><span><a href=\"#TimeSeries-Data---MLP---Keras\" data-toc-modified-id=\"TimeSeries-Data---MLP---Keras-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TimeSeries Data - MLP - Keras</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-the-data\" data-toc-modified-id=\"Prepare-the-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Prepare the data</a></span></li><li><span><a href=\"#Build,-Train-and-Evaluate-the-Model\" data-toc-modified-id=\"Build,-Train-and-Evaluate-the-Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Build, Train and Evaluate the Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e3865-64be-4bb2-ba0a-bbabe43f11c4",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptron <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bacc61-cd91-4a5a-aed5-6bc775308a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:1.18.5\n",
      "Pandas:1.2.4\n",
      "Matplotlib:3.3.4\n",
      "TensorFlow:1.15.5\n",
      "Keras:2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "print(\"NumPy:{}\".format(np.__version__))\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas:{}\".format(pd.__version__))\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "print(\"Matplotlib:{}\".format(mpl.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(123)\n",
    "print(\"TensorFlow:{}\".format(tf.__version__))\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "print(\"Keras:{}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57839770-9202-4a54-a495-e269ec62a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETSLIB_HOME = '../datasetslib'\n",
    "\n",
    "import sys\n",
    "if not DATASETSLIB_HOME in sys.path:\n",
    "    sys.path.append(DATASETSLIB_HOME)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datasetslib\n",
    "from datasetslib import util as dsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cecc681e-f9d7-4d9f-9457-559dd75e71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetslib.datasets_root = os.path.join(\"../\", 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c197d2-9dae-48d2-8352-8f08ddfe5b51",
   "metadata": {},
   "source": [
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b6731-f88b-4201-87c8-e7073a0c48cb",
   "metadata": {},
   "source": [
    "## Get the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4974bae-b03f-4240-9ba5-208db0029166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-a34f7bb347b5>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/essav/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/essav/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /home/essav/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/essav/datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\n",
    "    os.path.join(datasetslib.datasets_root, 'mnist'),\n",
    "    one_hot=True\n",
    ")\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels\n",
    "\n",
    "num_outputs = 10  # 0-9 digits\n",
    "num_inputs = 784  # total pixels (28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0310e7e-16d2-4fdd-b41b-d419b5dfc459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X_train): <class 'numpy.ndarray'>\n",
      "type(Y_test): <class 'numpy.ndarray'>\n",
      "X_train.shape: (55000, 784)\n",
      "Y_test.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"type(X_train):\", type(X_train))\n",
    "print(\"type(Y_test):\", type(Y_test))\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"Y_test.shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34aa27-128a-4806-9f96-357fe9ca63e2",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()## MLP in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c098245-5206-4c40-8e56-1d045a0df6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe41ac-f33d-4a1a-a4d1-f94953d68c76",
   "metadata": {},
   "source": [
    "#### Note on the `mlp()` function:\n",
    "\n",
    "Building the layers:\n",
    "* The tensors are given the names `w_<layer_num>` and `b_<layer_num>` respectively. Naming the tensors helps in the debugging and locating problems with the code.\n",
    "* The tensors are initialized with normal distribution using `tf.random_normal()`.\n",
    "* The *first* dimension of the weight tensor is the number of inputs from the previous layer. \n",
    "    * For the first hidden layer, the first dimension is `num_inputs`. \n",
    "* The *second* dimension of the weights tensor is the number of neurons in the current layer.\n",
    "* The biases are all one-dimensional tensors, where the dimension equals the number of neurons in the current layer.\n",
    "* The last hidden layer: \n",
    "    * In this case, the dimensions of the weights tensor are equal to the number of neurons in the last hidden layer and the *number of output targets*. \n",
    "    * The bias would be a tensor having a single dimension of the size of the *number of output features*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6221ab6a-e1d4-4ced-ba31-ad27cb70c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to **build** an MLP model.\n",
    "\n",
    "def mlp(\n",
    "    x,            # x is the input features tensor\n",
    "    num_inputs,   # num_inputs is the number of input features\n",
    "    num_outputs,  # num_outputs is the number of output targets\n",
    "    num_layers,   # num_layers is the number of hidden layers required\n",
    "    num_neurons   # num_neurons is the **list** containing the number of neurons for each layer\n",
    "):\n",
    "    print(\"========== BUILDING MODEL ==========\")\n",
    "    w = []  # Create a LIST to store W's for each layer\n",
    "    b = []  # Create a LIST to store b's for each layer\n",
    "    \n",
    "    # Run a loop for the number of hidden layers to create weights and bias tensors\n",
    "    # and append them to their respective lists:\n",
    "    for i in range(num_layers):\n",
    "        # Weights\n",
    "        w.append(\n",
    "            # Define a `Variable`...\n",
    "            tf.Variable(\n",
    "                # Initial value set via `random_normal()`\n",
    "                tf.random_normal(\n",
    "                    # Shape: \n",
    "                    #   - set to [num_inputs, num_neurons[i]] for 0th hidden layer, \n",
    "                    #   - set to [num_neurons[i - 1], num_neurons[i]] for other hidden layers.\n",
    "                    shape=[\n",
    "                        num_inputs if i == 0 else num_neurons[i - 1],  # shape[0]\n",
    "                        num_neurons[i]                                 # shape[1]\n",
    "                    ]\n",
    "                ),\n",
    "                name=\"w_{0:04d}\".format(i)\n",
    "            )\n",
    "        )\n",
    "        print(f\"Added W layer [{i}]: {w[i]}\")\n",
    "        # Biases\n",
    "        b.append(\n",
    "            tf.Variable(\n",
    "                tf.random_normal(\n",
    "                    [num_neurons[i]]\n",
    "                ),\n",
    "                name=\"b_{0:04d}\".format(i)\n",
    "            )\n",
    "        )\n",
    "        print(f\"Added b layer [{i}]: {b[i]}\")\n",
    "    \n",
    "    # Set up the *last* (output) layer:\n",
    "    # Weights:\n",
    "    w.append(\n",
    "        tf.Variable(\n",
    "            tf.random_normal(\n",
    "                [\n",
    "                    num_neurons[num_layers - 1] if num_layers > 0 else num_inputs,  # shape[0] \n",
    "                    num_outputs                                                     # shape[1]\n",
    "                ]\n",
    "            ), \n",
    "            name=\"w_out\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Added W layer [*output*]: {w[-1]}\")\n",
    "    # Biases:\n",
    "    b.append(\n",
    "        tf.Variable(\n",
    "            tf.random_normal([num_outputs]), \n",
    "            name=\"b_out\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Added b layer [*output*]: {b[-1]}\")\n",
    "    \n",
    "    # Define the model computation graph:\n",
    "    # `x` is input layer:\n",
    "    layer = x\n",
    "    # Add hidden layers:\n",
    "    for i in range(num_layers):\n",
    "        layer = tf.nn.relu(tf.matmul(layer, w[i]) + b[i])  # ReLU( W*x + b )\n",
    "    # Add output layer:\n",
    "    layer = tf.matmul(layer, w[num_layers]) + b[num_layers]  # W*x + b (no ReLU on last layer)\n",
    "    \n",
    "    print(\"========== BUILDING MODEL FINISHED ==========\")\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f1ecce-3b8c-4a8b-8464-462678c8870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_func(batch_size=100):\n",
    "    X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "    return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c80f31a-500a-488e-b26a-0a127aa961ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for the whole classification pipeline.\n",
    "\n",
    "def tensorflow_classification(\n",
    "    n_epochs, \n",
    "    n_batches,\n",
    "    batch_size, \n",
    "    batch_func,\n",
    "    model, \n",
    "    optimizer, \n",
    "    loss, \n",
    "    accuracy_function,\n",
    "    X_test, \n",
    "    Y_test\n",
    "):\n",
    "    # Debug info for my own satisfaction: ----------\n",
    "    _args = [\n",
    "        (\"n_epochs\", n_epochs), \n",
    "        (\"n_batches\", n_batches),\n",
    "        (\"batch_size\", batch_size), \n",
    "        (\"batch_func\", batch_func),\n",
    "        (\"model\", model), \n",
    "        (\"optimizer\", optimizer), \n",
    "        (\"loss\", loss), \n",
    "        (\"accuracy_function\", accuracy_function),\n",
    "        (\"X_test\", X_test), \n",
    "        (\"Y_test\", Y_test),\n",
    "    ]\n",
    "    for _name, _arg in _args:\n",
    "        print(f\"<{_name}>:\\ntype: {type(_arg)}\\n{_arg}\")\n",
    "        if \"shape\" in dir(_arg):\n",
    "            print(f\"shape: {_arg.shape}\")\n",
    "        print(\"-\" * 80)\n",
    "    # ----------------------------------------------\n",
    "    \n",
    "    with tf.Session() as tfs:\n",
    "        tfs.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Epoch iteration:\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            # Batch iteration:\n",
    "            for batch in range(n_batches):\n",
    "                X_batch, Y_batch = batch_func(batch_size)\n",
    "                feed_dict = {x: X_batch, y: Y_batch}\n",
    "                _, batch_loss = tfs.run([optimizer, loss], feed_dict)\n",
    "                epoch_loss += batch_loss  # NOTE: Accummulating epoch loss!\n",
    "            \n",
    "            average_loss = epoch_loss / n_batches\n",
    "            print(\"epoch: {0:04d}   TRAINING loss = {1:0.6f}\".format(epoch, average_loss))\n",
    "        \n",
    "        # Final accuracy, on the test set.\n",
    "        feed_dict = {x: X_test, y: Y_test}\n",
    "        accuracy_score = tfs.run(accuracy_function, feed_dict=feed_dict)\n",
    "        print(\"TEST accuracy={0:.8f}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1646a3-96de-4bb2-ad50-a15435d3bb28",
   "metadata": {},
   "source": [
    "### Case 1: No hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f48d0c6-7a08-456e-b743-212107766077",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 0\n",
    "num_neurons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31cee169-0380-4e21-92ad-07f393b1be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 100    n_batches: 550\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples / batch_size)\n",
    "print(f\"batch size: {batch_size}    n_batches: {n_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33b7231b-02fc-4c43-8202-4a4839c152bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images:\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs])\n",
    "# Target output:\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d75b76da-d40c-4bef-ab04-4cc8a4bd8ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BUILDING MODEL ==========\n",
      "Added W layer [*output*]: <tf.Variable 'w_out:0' shape=(784, 10) dtype=float32_ref>\n",
      "Added b layer [*output*]: <tf.Variable 'b_out:0' shape=(10,) dtype=float32_ref>\n",
      "========== BUILDING MODEL FINISHED ==========\n"
     ]
    }
   ],
   "source": [
    "# Build model.\n",
    "model = mlp(\n",
    "    x=x,\n",
    "    num_inputs=num_inputs,\n",
    "    num_outputs=num_outputs,\n",
    "    num_layers=num_layers,\n",
    "    num_neurons=num_neurons\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1977dca-7795-4975-b7f7-95f82c947c9b",
   "metadata": {},
   "source": [
    "#### Note on `tf.nn.softmax_cross_entropy_with_logits()`\n",
    "* When the `softmax_cross_entropy_with_logits()` function is used, make sure that the output is **unscaled** and has **not** been passed through the `softmax` activation function. \n",
    "* This function internally uses softmax to scale the output.\n",
    "* This function computes the softmax entropy between the model (the estimated value y) and the actual value of $y$. \n",
    "    * The entropy function is used when the output belongs to one class and not more than one class. \n",
    "    * As in our example, the image can only belong to one of the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18abf08d-514e-4850-8194-01bf9bd3dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function:\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95b44eb5-5928-4239-ad0e-4e3eb5f011aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer function:\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d07584c-0c75-41ec-a54b-258fea701f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define (test) accuracy metric function:\n",
    "predictions_check = tf.equal(tf.argmax(model, axis=1), tf.argmax(y, axis=1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f819f1-e0be-4e7c-98d1-fad3aad0e382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<n_epochs>:\n",
      "type: <class 'int'>\n",
      "50\n",
      "--------------------------------------------------------------------------------\n",
      "<n_batches>:\n",
      "type: <class 'int'>\n",
      "550\n",
      "--------------------------------------------------------------------------------\n",
      "<batch_size>:\n",
      "type: <class 'int'>\n",
      "100\n",
      "--------------------------------------------------------------------------------\n",
      "<batch_func>:\n",
      "type: <class 'function'>\n",
      "<function mnist_batch_func at 0x7fe388e64320>\n",
      "--------------------------------------------------------------------------------\n",
      "<model>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"add:0\", shape=(?, 10), dtype=float32)\n",
      "shape: (?, 10)\n",
      "--------------------------------------------------------------------------------\n",
      "<optimizer>:\n",
      "type: <class 'tensorflow.python.framework.ops.Operation'>\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_w_out/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b_out/ApplyGradientDescent\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<loss>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "shape: ()\n",
      "--------------------------------------------------------------------------------\n",
      "<accuracy_function>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "shape: ()\n",
      "--------------------------------------------------------------------------------\n",
      "<X_test>:\n",
      "type: <class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape: (10000, 784)\n",
      "--------------------------------------------------------------------------------\n",
      "<Y_test>:\n",
      "type: <class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape: (10000, 10)\n",
      "--------------------------------------------------------------------------------\n",
      "epoch: 0000   TRAINING loss = 8.718988\n",
      "epoch: 0001   TRAINING loss = 4.553448\n",
      "epoch: 0002   TRAINING loss = 3.185887\n",
      "epoch: 0003   TRAINING loss = 2.518076\n",
      "epoch: 0004   TRAINING loss = 2.126295\n",
      "epoch: 0005   TRAINING loss = 1.867260\n",
      "epoch: 0006   TRAINING loss = 1.684603\n",
      "epoch: 0007   TRAINING loss = 1.549024\n",
      "epoch: 0008   TRAINING loss = 1.443280\n",
      "epoch: 0009   TRAINING loss = 1.358628\n",
      "epoch: 0010   TRAINING loss = 1.288621\n",
      "epoch: 0011   TRAINING loss = 1.233475\n",
      "epoch: 0012   TRAINING loss = 1.181397\n",
      "epoch: 0013   TRAINING loss = 1.141080\n",
      "epoch: 0014   TRAINING loss = 1.103069\n",
      "epoch: 0015   TRAINING loss = 1.070154\n",
      "epoch: 0016   TRAINING loss = 1.041769\n",
      "epoch: 0017   TRAINING loss = 1.014983\n",
      "epoch: 0018   TRAINING loss = 0.990710\n",
      "epoch: 0019   TRAINING loss = 0.969396\n",
      "epoch: 0020   TRAINING loss = 0.947466\n",
      "epoch: 0021   TRAINING loss = 0.930238\n",
      "epoch: 0022   TRAINING loss = 0.914519\n",
      "epoch: 0023   TRAINING loss = 0.895788\n",
      "epoch: 0024   TRAINING loss = 0.882458\n",
      "epoch: 0025   TRAINING loss = 0.868816\n",
      "epoch: 0026   TRAINING loss = 0.855079\n",
      "epoch: 0027   TRAINING loss = 0.842330\n",
      "epoch: 0028   TRAINING loss = 0.831098\n",
      "epoch: 0029   TRAINING loss = 0.820385\n",
      "epoch: 0030   TRAINING loss = 0.808731\n",
      "epoch: 0031   TRAINING loss = 0.799837\n",
      "epoch: 0032   TRAINING loss = 0.790228\n",
      "epoch: 0033   TRAINING loss = 0.780881\n",
      "epoch: 0034   TRAINING loss = 0.771960\n",
      "epoch: 0035   TRAINING loss = 0.764033\n",
      "epoch: 0036   TRAINING loss = 0.755973\n",
      "epoch: 0037   TRAINING loss = 0.748366\n",
      "epoch: 0038   TRAINING loss = 0.741609\n",
      "epoch: 0039   TRAINING loss = 0.734234\n",
      "epoch: 0040   TRAINING loss = 0.726822\n",
      "epoch: 0041   TRAINING loss = 0.722161\n",
      "epoch: 0042   TRAINING loss = 0.714907\n",
      "epoch: 0043   TRAINING loss = 0.708079\n",
      "epoch: 0044   TRAINING loss = 0.702529\n",
      "epoch: 0045   TRAINING loss = 0.697674\n",
      "epoch: 0046   TRAINING loss = 0.691174\n",
      "epoch: 0047   TRAINING loss = 0.686239\n",
      "epoch: 0048   TRAINING loss = 0.681047\n",
      "epoch: 0049   TRAINING loss = 0.675893\n",
      "TEST accuracy=0.85970002\n"
     ]
    }
   ],
   "source": [
    "# Execute classification pipeline!\n",
    "tensorflow_classification(\n",
    "    n_epochs=n_epochs,\n",
    "    n_batches=n_batches,\n",
    "    batch_size=batch_size,\n",
    "    batch_func=mnist_batch_func,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    accuracy_function=accuracy_function,\n",
    "    X_test=mnist.test.images,\n",
    "    Y_test=mnist.test.labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499b2c5-9238-4090-9086-988a1b5f2e89",
   "metadata": {},
   "source": [
    "### Case 2: 1 Hiden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdd2bf22-409e-4e91-a329-8db342fc1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ce3246a-790e-4163-8fb9-d566a106c942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BUILDING MODEL ==========\n",
      "Added W layer [0]: <tf.Variable 'w_0000:0' shape=(784, 8) dtype=float32_ref>\n",
      "Added b layer [0]: <tf.Variable 'b_0000:0' shape=(8,) dtype=float32_ref>\n",
      "Added W layer [*output*]: <tf.Variable 'w_out:0' shape=(8, 10) dtype=float32_ref>\n",
      "Added b layer [*output*]: <tf.Variable 'b_out:0' shape=(10,) dtype=float32_ref>\n",
      "========== BUILDING MODEL FINISHED ==========\n",
      "<n_epochs>:\n",
      "type: <class 'int'>\n",
      "50\n",
      "--------------------------------------------------------------------------------\n",
      "<n_batches>:\n",
      "type: <class 'int'>\n",
      "550\n",
      "--------------------------------------------------------------------------------\n",
      "<batch_size>:\n",
      "type: <class 'int'>\n",
      "100\n",
      "--------------------------------------------------------------------------------\n",
      "<batch_func>:\n",
      "type: <class 'function'>\n",
      "<function mnist_batch_func at 0x7fe388e64320>\n",
      "--------------------------------------------------------------------------------\n",
      "<model>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
      "shape: (?, 10)\n",
      "--------------------------------------------------------------------------------\n",
      "<optimizer>:\n",
      "type: <class 'tensorflow.python.framework.ops.Operation'>\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_w_0000/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b_0000/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_w_out/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b_out/ApplyGradientDescent\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<loss>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "shape: ()\n",
      "--------------------------------------------------------------------------------\n",
      "<accuracy_function>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "shape: ()\n",
      "--------------------------------------------------------------------------------\n",
      "<X_test>:\n",
      "type: <class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape: (10000, 784)\n",
      "--------------------------------------------------------------------------------\n",
      "<Y_test>:\n",
      "type: <class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape: (10000, 10)\n",
      "--------------------------------------------------------------------------------\n",
      "epoch: 0000   TRAINING loss = 4.270433\n",
      "epoch: 0001   TRAINING loss = 2.324518\n",
      "epoch: 0002   TRAINING loss = 2.196275\n",
      "epoch: 0003   TRAINING loss = 2.123891\n",
      "epoch: 0004   TRAINING loss = 2.065704\n",
      "epoch: 0005   TRAINING loss = 2.011010\n",
      "epoch: 0006   TRAINING loss = 1.952843\n",
      "epoch: 0007   TRAINING loss = 1.889942\n",
      "epoch: 0008   TRAINING loss = 1.821061\n",
      "epoch: 0009   TRAINING loss = 1.752042\n",
      "epoch: 0010   TRAINING loss = 1.687452\n",
      "epoch: 0011   TRAINING loss = 1.629051\n",
      "epoch: 0012   TRAINING loss = 1.574134\n",
      "epoch: 0013   TRAINING loss = 1.524050\n",
      "epoch: 0014   TRAINING loss = 1.475706\n",
      "epoch: 0015   TRAINING loss = 1.432020\n",
      "epoch: 0016   TRAINING loss = 1.392866\n",
      "epoch: 0017   TRAINING loss = 1.357575\n",
      "epoch: 0018   TRAINING loss = 1.323194\n",
      "epoch: 0019   TRAINING loss = 1.292265\n",
      "epoch: 0020   TRAINING loss = 1.261374\n",
      "epoch: 0021   TRAINING loss = 1.232096\n",
      "epoch: 0022   TRAINING loss = 1.204361\n",
      "epoch: 0023   TRAINING loss = 1.176521\n",
      "epoch: 0024   TRAINING loss = 1.149570\n",
      "epoch: 0025   TRAINING loss = 1.124347\n",
      "epoch: 0026   TRAINING loss = 1.099691\n",
      "epoch: 0027   TRAINING loss = 1.076589\n",
      "epoch: 0028   TRAINING loss = 1.055773\n",
      "epoch: 0029   TRAINING loss = 1.034650\n",
      "epoch: 0030   TRAINING loss = 1.015529\n",
      "epoch: 0031   TRAINING loss = 0.997600\n",
      "epoch: 0032   TRAINING loss = 0.980477\n",
      "epoch: 0033   TRAINING loss = 0.962642\n",
      "epoch: 0034   TRAINING loss = 0.947568\n",
      "epoch: 0035   TRAINING loss = 0.931806\n",
      "epoch: 0036   TRAINING loss = 0.917608\n",
      "epoch: 0037   TRAINING loss = 0.903759\n",
      "epoch: 0038   TRAINING loss = 0.891128\n",
      "epoch: 0039   TRAINING loss = 0.878801\n",
      "epoch: 0040   TRAINING loss = 0.868422\n",
      "epoch: 0041   TRAINING loss = 0.855552\n",
      "epoch: 0042   TRAINING loss = 0.845638\n",
      "epoch: 0043   TRAINING loss = 0.834526\n",
      "epoch: 0044   TRAINING loss = 0.826289\n",
      "epoch: 0045   TRAINING loss = 0.815892\n",
      "epoch: 0046   TRAINING loss = 0.806685\n",
      "epoch: 0047   TRAINING loss = 0.797612\n",
      "epoch: 0048   TRAINING loss = 0.788614\n",
      "epoch: 0049   TRAINING loss = 0.777488\n",
      "TEST accuracy=0.76690000\n"
     ]
    }
   ],
   "source": [
    "num_layers = 1 \n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(8)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(\n",
    "    x=x, \n",
    "    num_inputs=num_inputs, \n",
    "    num_outputs=num_outputs, \n",
    "    num_layers=num_layers, \n",
    "    num_neurons=num_neurons\n",
    ")\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "# optimizer function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(\n",
    "    n_epochs=n_epochs, \n",
    "    n_batches=n_batches, \n",
    "    batch_size=batch_size, \n",
    "    batch_func=mnist_batch_func, \n",
    "    model = model, \n",
    "    optimizer = optimizer, \n",
    "    loss = loss, \n",
    "    accuracy_function = accuracy_function, \n",
    "    X_test = mnist.test.images, \n",
    "    Y_test = mnist.test.labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d3ed7-24f1-4578-86f5-a96fdf4f9dc5",
   "metadata": {},
   "source": [
    "### Case 3: 2 Hiden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9235460a-91a9-4ec1-94b9-afbf2fb6b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3191d3dd-c6fa-478a-9810-e448c21e09d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BUILDING MODEL ==========\n",
      "Added W layer [0]: <tf.Variable 'w_0000:0' shape=(784, 256) dtype=float32_ref>\n",
      "Added b layer [0]: <tf.Variable 'b_0000:0' shape=(256,) dtype=float32_ref>\n",
      "Added W layer [1]: <tf.Variable 'w_0001:0' shape=(256, 256) dtype=float32_ref>\n",
      "Added b layer [1]: <tf.Variable 'b_0001:0' shape=(256,) dtype=float32_ref>\n",
      "Added W layer [*output*]: <tf.Variable 'w_out:0' shape=(256, 10) dtype=float32_ref>\n",
      "Added b layer [*output*]: <tf.Variable 'b_out:0' shape=(10,) dtype=float32_ref>\n",
      "========== BUILDING MODEL FINISHED ==========\n",
      "<n_epochs>:\n",
      "type: <class 'int'>\n",
      "50\n",
      "--------------------------------------------------------------------------------\n",
      "<n_batches>:\n",
      "type: <class 'int'>\n",
      "550\n",
      "--------------------------------------------------------------------------------\n",
      "<batch_size>:\n",
      "type: <class 'int'>\n",
      "100\n",
      "--------------------------------------------------------------------------------\n",
      "<batch_func>:\n",
      "type: <class 'function'>\n",
      "<function mnist_batch_func at 0x7fe388e64320>\n",
      "--------------------------------------------------------------------------------\n",
      "<model>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"add_2:0\", shape=(?, 10), dtype=float32)\n",
      "shape: (?, 10)\n",
      "--------------------------------------------------------------------------------\n",
      "<optimizer>:\n",
      "type: <class 'tensorflow.python.framework.ops.Operation'>\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_w_0000/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b_0000/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_w_0001/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b_0001/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_w_out/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_b_out/ApplyGradientDescent\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<loss>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "shape: ()\n",
      "--------------------------------------------------------------------------------\n",
      "<accuracy_function>:\n",
      "type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "shape: ()\n",
      "--------------------------------------------------------------------------------\n",
      "<X_test>:\n",
      "type: <class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape: (10000, 784)\n",
      "--------------------------------------------------------------------------------\n",
      "<Y_test>:\n",
      "type: <class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "shape: (10000, 10)\n",
      "--------------------------------------------------------------------------------\n",
      "epoch: 0000   TRAINING loss = 54.380210\n",
      "epoch: 0001   TRAINING loss = 13.305868\n",
      "epoch: 0002   TRAINING loss = 8.225230\n",
      "epoch: 0003   TRAINING loss = 5.823687\n",
      "epoch: 0004   TRAINING loss = 4.382273\n",
      "epoch: 0005   TRAINING loss = 3.465521\n",
      "epoch: 0006   TRAINING loss = 2.845068\n",
      "epoch: 0007   TRAINING loss = 2.308406\n",
      "epoch: 0008   TRAINING loss = 1.948490\n",
      "epoch: 0009   TRAINING loss = 1.591593\n",
      "epoch: 0010   TRAINING loss = 1.385815\n",
      "epoch: 0011   TRAINING loss = 1.170108\n",
      "epoch: 0012   TRAINING loss = 1.017736\n",
      "epoch: 0013   TRAINING loss = 0.873678\n",
      "epoch: 0014   TRAINING loss = 0.747488\n",
      "epoch: 0015   TRAINING loss = 0.654172\n",
      "epoch: 0016   TRAINING loss = 0.575668\n",
      "epoch: 0017   TRAINING loss = 0.490036\n",
      "epoch: 0018   TRAINING loss = 0.437087\n",
      "epoch: 0019   TRAINING loss = 0.366161\n",
      "epoch: 0020   TRAINING loss = 0.332787\n",
      "epoch: 0021   TRAINING loss = 0.304903\n",
      "epoch: 0022   TRAINING loss = 0.267598\n",
      "epoch: 0023   TRAINING loss = 0.235644\n",
      "epoch: 0024   TRAINING loss = 0.207793\n",
      "epoch: 0025   TRAINING loss = 0.182261\n",
      "epoch: 0026   TRAINING loss = 0.166722\n",
      "epoch: 0027   TRAINING loss = 0.149241\n",
      "epoch: 0028   TRAINING loss = 0.131825\n",
      "epoch: 0029   TRAINING loss = 0.120119\n",
      "epoch: 0030   TRAINING loss = 0.106858\n",
      "epoch: 0031   TRAINING loss = 0.094361\n",
      "epoch: 0032   TRAINING loss = 0.085417\n",
      "epoch: 0033   TRAINING loss = 0.069348\n",
      "epoch: 0034   TRAINING loss = 0.065010\n",
      "epoch: 0035   TRAINING loss = 0.056305\n",
      "epoch: 0036   TRAINING loss = 0.054157\n",
      "epoch: 0037   TRAINING loss = 0.049813\n",
      "epoch: 0038   TRAINING loss = 0.045772\n",
      "epoch: 0039   TRAINING loss = 0.037430\n",
      "epoch: 0040   TRAINING loss = 0.037472\n",
      "epoch: 0041   TRAINING loss = 0.029992\n",
      "epoch: 0042   TRAINING loss = 0.024284\n",
      "epoch: 0043   TRAINING loss = 0.021898\n",
      "epoch: 0044   TRAINING loss = 0.016973\n",
      "epoch: 0045   TRAINING loss = 0.016332\n",
      "epoch: 0046   TRAINING loss = 0.014079\n",
      "epoch: 0047   TRAINING loss = 0.011044\n",
      "epoch: 0048   TRAINING loss = 0.010220\n",
      "epoch: 0049   TRAINING loss = 0.008092\n",
      "TEST accuracy=0.93220001\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\", shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\", shape=[None, num_outputs]) \n",
    "\n",
    "model = mlp(\n",
    "    x=x, \n",
    "    num_inputs=num_inputs, \n",
    "    num_outputs=num_outputs, \n",
    "    num_layers=num_layers, \n",
    "    num_neurons=num_neurons\n",
    ")\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "# optimizer function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "predictions_check = tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n",
    "\n",
    "tensorflow_classification(\n",
    "    n_epochs=n_epochs, \n",
    "    n_batches=n_batches, \n",
    "    batch_size=batch_size, \n",
    "    batch_func=mnist_batch_func, \n",
    "    model = model, \n",
    "    optimizer = optimizer, \n",
    "    loss = loss, \n",
    "    accuracy_function = accuracy_function, \n",
    "    X_test = mnist.test.images, \n",
    "    Y_test = mnist.test.labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf090c-e5d1-46ca-a8eb-89f929694035",
   "metadata": {},
   "source": [
    "## MLP in `Keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9702853-433d-4ab0-a302-91fbeaa578cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: import Keras directly from TF. \n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84d24316-aa55-4b1c-8329-02fe0bfd427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a665818-bb57-4603-95f3-d3d22c49e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 1.1096 - acc: 0.7276\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.4487 - acc: 0.8798\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.3598 - acc: 0.8991\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.3199 - acc: 0.9085\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.2943 - acc: 0.9159\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.2748 - acc: 0.9212\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.2582 - acc: 0.9264\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.2442 - acc: 0.9307\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.2316 - acc: 0.9342\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.2200 - acc: 0.9369\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.2098 - acc: 0.9401\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.2006 - acc: 0.9428\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1919 - acc: 0.9456\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1839 - acc: 0.9471\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1764 - acc: 0.9499\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1695 - acc: 0.9516\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1632 - acc: 0.9533\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1569 - acc: 0.9551\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1516 - acc: 0.9570\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1464 - acc: 0.9586\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1413 - acc: 0.9598\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1367 - acc: 0.9614\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1326 - acc: 0.9628\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1281 - acc: 0.9645\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1241 - acc: 0.9653\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1207 - acc: 0.9659\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1171 - acc: 0.9675\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1136 - acc: 0.9688\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1104 - acc: 0.9697\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.1074 - acc: 0.9707\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1046 - acc: 0.9709\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.1017 - acc: 0.9720\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0991 - acc: 0.9725\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0967 - acc: 0.9729\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0942 - acc: 0.9737\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0921 - acc: 0.9746\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.0895 - acc: 0.9752\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.0874 - acc: 0.9759\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0850 - acc: 0.9766\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 1s 12us/sample - loss: 0.0833 - acc: 0.9769\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0813 - acc: 0.9776\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0793 - acc: 0.9782\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0775 - acc: 0.9787\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0757 - acc: 0.9793\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0742 - acc: 0.9795\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0725 - acc: 0.9804\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0708 - acc: 0.9806\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0693 - acc: 0.9813\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0679 - acc: 0.9813\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 1s 13us/sample - loss: 0.0664 - acc: 0.9823\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.0892 - acc: 0.9735\n",
      "\n",
      "Test loss: 0.08924152733683587\n",
      "Test accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "# 2 Hidden layers of 256 neurons.\n",
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=num_neurons[0], \n",
    "        activation='relu',  # NOTE: can define activation in keras layer.\n",
    "        input_shape=(num_inputs,)\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=num_neurons[1], \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=num_outputs, \n",
    "        activation='softmax'\n",
    "    )\n",
    ")\n",
    "model.summary()  # Prints model summary.\n",
    "\n",
    "# Don't forget to compile!\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # Predefined categorical_crossentropy loss.\n",
    "    optimizer=SGD(lr=learning_rate),  # Pass optimiser function.\n",
    "    metrics=['accuracy']              # Predefined accuracy metric.\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs\n",
    ")\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)  # `.evaluate()` call.\n",
    "# ^ Note what this returns - in this case, it's a tuple with (loss, accuracy_metric)!\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43cb8b-8dd3-46d3-a339-6d6f9ec94344",
   "metadata": {},
   "source": [
    "## MLP in `TFLearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85155d7b-3433-4c9f-8069-70388f06fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /mnt/space/miniconda3/envs/py37_tf1/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25cfdbcc-672a-47a0-aaf5-098330dff132",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "295c78f9-dc7d-44f8-b71a-733a6c61d858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 27499  | total loss: \u001b[1m\u001b[32m0.09476\u001b[0m\u001b[0m | time: 1.321s\n",
      "| SGD | epoch: 050 | loss: 0.09476 - acc: 0.9693 -- iter: 54900/55000\n",
      "Training Step: 27500  | total loss: \u001b[1m\u001b[32m0.09512\u001b[0m\u001b[0m | time: 1.323s\n",
      "| SGD | epoch: 050 | loss: 0.09512 - acc: 0.9694 -- iter: 55000/55000\n",
      "--\n",
      "Test accuracy: 0.9662\n"
     ]
    }
   ],
   "source": [
    "# 2 Hidden layers of 256 neurons.\n",
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "# Build deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, num_inputs])\n",
    "dense1 = tflearn.fully_connected(input_layer, num_neurons[0], activation='relu')\n",
    "dense2 = tflearn.fully_connected(dense1, num_neurons[1], activation='relu')\n",
    "softmax = tflearn.fully_connected(dense2, num_outputs, activation='softmax')\n",
    "\n",
    "optimizer = tflearn.SGD(learning_rate=learning_rate)\n",
    "# Note:\n",
    "# Rather strange step in TFLearn 🤔...\n",
    "# \"The regression layer is used in TFLearn to apply a regression (linear or logistic) to the provided input.\"\n",
    "net = tflearn.regression(\n",
    "    softmax, \n",
    "    optimizer=optimizer, \n",
    "    metric=tflearn.metrics.Accuracy(), \n",
    "    loss='categorical_crossentropy'\n",
    ")\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    n_epoch=n_epochs, \n",
    "    batch_size=batch_size, \n",
    "    show_metric=True, \n",
    "    run_id='dense_model'\n",
    ")\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1828d3-32d9-4086-b33b-1a4ac0b2a125",
   "metadata": {},
   "source": [
    "# TimeSeries Data - MLP - Keras\n",
    "\n",
    "**Note**: This is time series data as converted to supervised format (shifting window)\n",
    "\n",
    "We have seen examples of classification for image data; now let's look at regression for time series data. \n",
    "\n",
    "We shall build and use MLP for a smaller **univariate** time series dataset known as \"the international airline passengers dataset\". This dataset contains the total number of passengers over the years. The dataset is available at the following link:\n",
    "* https://www.kaggle.com/andreazzini/international-airline-passengers/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea97d4-b9fa-4764-b5ad-24ff21a61396",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50e3720a-4a21-4154-9023-2d59b7532927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataframe = pd.read_csv(\n",
    "    os.path.join(datasetslib.datasets_root, 'ts-data', 'international-airline-passengers.csv'), \n",
    "    usecols=[1],\n",
    "    header=0\n",
    ").dropna()  \n",
    "# ^ Note: dropna() added by ES as had to use a \"international-airline-passengers.csv\" not \"international-airline-passengers-cleaned.csv\"\n",
    "\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02ce0493-d7ca-450b-bfd3-17273da26f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(dataset).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab1bdc9c-1b63-4438-8db0-ae11c1486b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "# scaler = skpp.MinMaxScaler(feature_range=(0, 1))\n",
    "# normalized_dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8abfe-cb9c-4269-b956-ca40df1d5efa",
   "metadata": {},
   "source": [
    "### Note on time series (univariate, single time-series) splitting:\n",
    "With a utility function from the datasetslib , we split the dataset into test and train sets. \n",
    "\n",
    "For time series datasets, we have a separate function that does not shuffle the observations because for time series regression we need to maintain the order of the observations.\n",
    "\n",
    "We use 67 percent data for training and 33 percent for testing. \n",
    "\n",
    "You may want to try the example with a different ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3d1a990-bb1e-4921-bd74-76759cd8c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 48\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train, test = dsu.train_test_split(dataset, train_size=0.67)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d0f19e1-b051-44a8-be70-0975a78166bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape (96, 1)\n",
      "test.shape (48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train.shape\", train.shape)\n",
    "print(\"test.shape\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148714d0-42a0-4902-a352-5e29ab657b5a",
   "metadata": {},
   "source": [
    "#### Note on converting to \"supervised format\" of dataset.\n",
    "For time series regression, we convert the dataset to build a supervised data set.\n",
    "\n",
    "We use a **lag of two time steps** in this example. \n",
    "\n",
    "We set `n_x` to 2 and the `mvts_to_xy()` function returns the input and output (`X` and `Y`) train and test sets such that \n",
    "* `X` has values for time ${t-1,t}$ in two columns and \n",
    "* `Y` has values for time ${t+1}$ in one column. \n",
    "\n",
    "Our learning algorithm assumes that values at time $t+1$ can be learned by finding the relationship between values for time ${t-1, t, t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e176b00b-ec91-4f72-a62b-c9175c74ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t-1,t and Y=t+1\n",
    "n_x = 2\n",
    "n_y = 1\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = dsu.mvts_to_xy(train, test, n_x=n_x, n_y=n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a7ababb-b4f9-49ac-a2a0-66ddca139536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (94, 2)\n",
      "Y_train.shape (94, 1)\n",
      "X_test.shape (46, 2)\n",
      "Y_test.shape (46, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"Y_train.shape\", Y_train.shape)\n",
    "\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"Y_test.shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa11e72-f894-4af0-8294-af43306cc49a",
   "metadata": {},
   "source": [
    "## Build, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0eb6c07c-d3e0-4052-a8f9-d08b2367a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "331d1f42-66a2-4422-96ee-809cacf64b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3a3db15-3acb-4f27-8c1e-dc929da11436",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 94 samples\n",
      "Epoch 1/500\n",
      "94/94 [==============================] - 0s 1ms/sample - loss: 103547.5421\n",
      "Epoch 2/500\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 59254.5534\n",
      "Epoch 3/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 36409.7191\n",
      "Epoch 4/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 18081.6774\n",
      "Epoch 5/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 5946.2472\n",
      "Epoch 6/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 1979.3032\n",
      "Epoch 7/500\n",
      "94/94 [==============================] - 0s 399us/sample - loss: 1456.6801\n",
      "Epoch 8/500\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 1385.5593\n",
      "Epoch 9/500\n",
      "94/94 [==============================] - 0s 451us/sample - loss: 1334.6277\n",
      "Epoch 10/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 1288.5364\n",
      "Epoch 11/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 1246.2014\n",
      "Epoch 12/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 1206.6832\n",
      "Epoch 13/500\n",
      "94/94 [==============================] - 0s 490us/sample - loss: 1169.5307\n",
      "Epoch 14/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 1134.0419\n",
      "Epoch 15/500\n",
      "94/94 [==============================] - 0s 461us/sample - loss: 1102.1193\n",
      "Epoch 16/500\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 1075.6816\n",
      "Epoch 17/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 1053.8731\n",
      "Epoch 18/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 1033.9251\n",
      "Epoch 19/500\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 1016.4600\n",
      "Epoch 20/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 1000.2094\n",
      "Epoch 21/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 984.3612\n",
      "Epoch 22/500\n",
      "94/94 [==============================] - 0s 486us/sample - loss: 969.0889\n",
      "Epoch 23/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 953.8520\n",
      "Epoch 24/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 938.7375\n",
      "Epoch 25/500\n",
      "94/94 [==============================] - 0s 456us/sample - loss: 923.7524\n",
      "Epoch 26/500\n",
      "94/94 [==============================] - 0s 452us/sample - loss: 908.9181\n",
      "Epoch 27/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 894.2505\n",
      "Epoch 28/500\n",
      "94/94 [==============================] - 0s 456us/sample - loss: 879.7654\n",
      "Epoch 29/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 865.4768\n",
      "Epoch 30/500\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 851.3998\n",
      "Epoch 31/500\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 837.5460\n",
      "Epoch 32/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 823.9295\n",
      "Epoch 33/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 810.5597\n",
      "Epoch 34/500\n",
      "94/94 [==============================] - 0s 498us/sample - loss: 797.4496\n",
      "Epoch 35/500\n",
      "94/94 [==============================] - 0s 488us/sample - loss: 784.6205\n",
      "Epoch 36/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 772.0539\n",
      "Epoch 37/500\n",
      "94/94 [==============================] - 0s 503us/sample - loss: 759.7769\n",
      "Epoch 38/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 747.7956\n",
      "Epoch 39/500\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 736.1173\n",
      "Epoch 40/500\n",
      "94/94 [==============================] - 0s 456us/sample - loss: 724.7508\n",
      "Epoch 41/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 713.7021\n",
      "Epoch 42/500\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 702.8341\n",
      "Epoch 43/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 692.6656\n",
      "Epoch 44/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 682.3634\n",
      "Epoch 45/500\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 672.9009\n",
      "Epoch 46/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 663.4356\n",
      "Epoch 47/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 654.2519\n",
      "Epoch 48/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 645.8024\n",
      "Epoch 49/500\n",
      "94/94 [==============================] - 0s 447us/sample - loss: 637.2010\n",
      "Epoch 50/500\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 629.4689\n",
      "Epoch 51/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 621.7323\n",
      "Epoch 52/500\n",
      "94/94 [==============================] - 0s 459us/sample - loss: 614.2645\n",
      "Epoch 53/500\n",
      "94/94 [==============================] - 0s 588us/sample - loss: 607.5464\n",
      "Epoch 54/500\n",
      "94/94 [==============================] - 0s 399us/sample - loss: 600.8387\n",
      "Epoch 55/500\n",
      "94/94 [==============================] - 0s 400us/sample - loss: 594.3906\n",
      "Epoch 56/500\n",
      "94/94 [==============================] - 0s 466us/sample - loss: 588.6659\n",
      "Epoch 57/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 582.9536\n",
      "Epoch 58/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 577.4791\n",
      "Epoch 59/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 572.6969\n",
      "Epoch 60/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 567.9231\n",
      "Epoch 61/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 563.3564\n",
      "Epoch 62/500\n",
      "94/94 [==============================] - 0s 466us/sample - loss: 559.4452\n",
      "Epoch 63/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 555.5337\n",
      "Epoch 64/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 551.9422\n",
      "Epoch 65/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 548.6085\n",
      "Epoch 66/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 545.3834\n",
      "Epoch 67/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 542.7071\n",
      "Epoch 68/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 540.0226\n",
      "Epoch 69/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 537.5863\n",
      "Epoch 70/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 535.3524\n",
      "Epoch 71/500\n",
      "94/94 [==============================] - 0s 467us/sample - loss: 533.3033\n",
      "Epoch 72/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 531.4278\n",
      "Epoch 73/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 529.7145\n",
      "Epoch 74/500\n",
      "94/94 [==============================] - 0s 510us/sample - loss: 528.1523\n",
      "Epoch 75/500\n",
      "94/94 [==============================] - 0s 509us/sample - loss: 526.7302\n",
      "Epoch 76/500\n",
      "94/94 [==============================] - 0s 401us/sample - loss: 525.4378\n",
      "Epoch 77/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 524.2652\n",
      "Epoch 78/500\n",
      "94/94 [==============================] - 0s 507us/sample - loss: 523.2022\n",
      "Epoch 79/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 522.2398\n",
      "Epoch 80/500\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 521.3695\n",
      "Epoch 81/500\n",
      "94/94 [==============================] - 0s 453us/sample - loss: 520.5994\n",
      "Epoch 82/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 519.9044\n",
      "Epoch 83/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 519.2514\n",
      "Epoch 84/500\n",
      "94/94 [==============================] - 0s 459us/sample - loss: 518.6560\n",
      "Epoch 85/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 518.1159\n",
      "Epoch 86/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 517.6252\n",
      "Epoch 87/500\n",
      "94/94 [==============================] - 0s 421us/sample - loss: 517.1793\n",
      "Epoch 88/500\n",
      "94/94 [==============================] - 0s 403us/sample - loss: 516.7925\n",
      "Epoch 89/500\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 516.4285\n",
      "Epoch 90/500\n",
      "94/94 [==============================] - 0s 491us/sample - loss: 516.0944\n",
      "Epoch 91/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 515.7882\n",
      "Epoch 92/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 515.5072\n",
      "Epoch 93/500\n",
      "94/94 [==============================] - 0s 475us/sample - loss: 515.2477\n",
      "Epoch 94/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 515.0078\n",
      "Epoch 95/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 514.7668\n",
      "Epoch 96/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 514.5436\n",
      "Epoch 97/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 514.4724\n",
      "Epoch 98/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 514.3134\n",
      "Epoch 99/500\n",
      "94/94 [==============================] - 0s 515us/sample - loss: 514.1507\n",
      "Epoch 100/500\n",
      "94/94 [==============================] - 0s 499us/sample - loss: 513.9951\n",
      "Epoch 101/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 513.8812\n",
      "Epoch 102/500\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 513.3951\n",
      "Epoch 103/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 512.9730\n",
      "Epoch 104/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 513.2466\n",
      "Epoch 105/500\n",
      "94/94 [==============================] - 0s 522us/sample - loss: 512.4439\n",
      "Epoch 106/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 513.1105\n",
      "Epoch 107/500\n",
      "94/94 [==============================] - 0s 451us/sample - loss: 512.5241\n",
      "Epoch 108/500\n",
      "94/94 [==============================] - 0s 491us/sample - loss: 512.0972\n",
      "Epoch 109/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 512.8449\n",
      "Epoch 110/500\n",
      "94/94 [==============================] - 0s 469us/sample - loss: 512.0563\n",
      "Epoch 111/500\n",
      "94/94 [==============================] - 0s 450us/sample - loss: 512.5016\n",
      "Epoch 112/500\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 511.7661\n",
      "Epoch 113/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 512.1736\n",
      "Epoch 114/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 512.0121\n",
      "Epoch 115/500\n",
      "94/94 [==============================] - 0s 452us/sample - loss: 511.4789\n",
      "Epoch 116/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 511.9380\n",
      "Epoch 117/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 511.2480\n",
      "Epoch 118/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 511.6365\n",
      "Epoch 119/500\n",
      "94/94 [==============================] - 0s 456us/sample - loss: 511.6137\n",
      "Epoch 120/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 510.8972\n",
      "Epoch 121/500\n",
      "94/94 [==============================] - 0s 492us/sample - loss: 511.3809\n",
      "Epoch 122/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 510.7654\n",
      "Epoch 123/500\n",
      "94/94 [==============================] - 0s 452us/sample - loss: 511.2474\n",
      "Epoch 124/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 510.6334\n",
      "Epoch 125/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 510.6300\n",
      "Epoch 126/500\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 510.9539\n",
      "Epoch 127/500\n",
      "94/94 [==============================] - 0s 473us/sample - loss: 510.2312\n",
      "Epoch 128/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 510.9001\n",
      "Epoch 129/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 510.2715\n",
      "Epoch 130/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 510.1006\n",
      "Epoch 131/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 510.5982\n",
      "Epoch 132/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 509.9254\n",
      "Epoch 133/500\n",
      "94/94 [==============================] - 0s 474us/sample - loss: 510.4194\n",
      "Epoch 134/500\n",
      "94/94 [==============================] - 0s 565us/sample - loss: 509.7902\n",
      "Epoch 135/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 509.7703\n",
      "Epoch 136/500\n",
      "94/94 [==============================] - 0s 487us/sample - loss: 509.9919\n",
      "Epoch 137/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 509.4468\n",
      "Epoch 138/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 509.9181\n",
      "Epoch 139/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 509.4300\n",
      "Epoch 140/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 509.1625\n",
      "Epoch 141/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 509.2486\n",
      "Epoch 142/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 509.2760\n",
      "Epoch 143/500\n",
      "94/94 [==============================] - 0s 502us/sample - loss: 509.3540\n",
      "Epoch 144/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 508.9556\n",
      "Epoch 145/500\n",
      "94/94 [==============================] - 0s 466us/sample - loss: 508.7112\n",
      "Epoch 146/500\n",
      "94/94 [==============================] - 0s 470us/sample - loss: 508.8953\n",
      "Epoch 147/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 508.8418\n",
      "Epoch 148/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 508.8769\n",
      "Epoch 149/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 508.3349\n",
      "Epoch 150/500\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 508.7838\n",
      "Epoch 151/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 508.3257\n",
      "Epoch 152/500\n",
      "94/94 [==============================] - 0s 470us/sample - loss: 507.8948\n",
      "Epoch 153/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 508.2926\n",
      "Epoch 154/500\n",
      "94/94 [==============================] - 0s 479us/sample - loss: 508.1793\n",
      "Epoch 155/500\n",
      "94/94 [==============================] - 0s 463us/sample - loss: 508.3841\n",
      "Epoch 156/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 507.7679\n",
      "Epoch 157/500\n",
      "94/94 [==============================] - 0s 453us/sample - loss: 508.1778\n",
      "Epoch 158/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 507.5838\n",
      "Epoch 159/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 508.0144\n",
      "Epoch 160/500\n",
      "94/94 [==============================] - 0s 421us/sample - loss: 507.4097\n",
      "Epoch 161/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 507.8518\n",
      "Epoch 162/500\n",
      "94/94 [==============================] - 0s 411us/sample - loss: 507.2388\n",
      "Epoch 163/500\n",
      "94/94 [==============================] - 0s 460us/sample - loss: 507.6890\n",
      "Epoch 164/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 507.2611\n",
      "Epoch 165/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 507.0235\n",
      "Epoch 166/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 507.2801\n",
      "Epoch 167/500\n",
      "94/94 [==============================] - 0s 512us/sample - loss: 506.8858\n",
      "Epoch 168/500\n",
      "94/94 [==============================] - 0s 401us/sample - loss: 507.1449\n",
      "Epoch 169/500\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 506.7163\n",
      "Epoch 170/500\n",
      "94/94 [==============================] - 0s 642us/sample - loss: 506.8447\n",
      "Epoch 171/500\n",
      "94/94 [==============================] - 0s 398us/sample - loss: 506.5210\n",
      "Epoch 172/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 506.8640\n",
      "Epoch 173/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 506.3754\n",
      "Epoch 174/500\n",
      "94/94 [==============================] - 0s 455us/sample - loss: 506.7214\n",
      "Epoch 175/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 506.2154\n",
      "Epoch 176/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 506.5758\n",
      "Epoch 177/500\n",
      "94/94 [==============================] - 0s 447us/sample - loss: 506.0578\n",
      "Epoch 178/500\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 506.4301\n",
      "Epoch 179/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 505.9032\n",
      "Epoch 180/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 506.2842\n",
      "Epoch 181/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 505.7512\n",
      "Epoch 182/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 506.1395\n",
      "Epoch 183/500\n",
      "94/94 [==============================] - 0s 470us/sample - loss: 505.6019\n",
      "Epoch 184/500\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 505.9951\n",
      "Epoch 185/500\n",
      "94/94 [==============================] - 0s 467us/sample - loss: 505.4553\n",
      "Epoch 186/500\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 505.8518\n",
      "Epoch 187/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 505.3107\n",
      "Epoch 188/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 505.7097\n",
      "Epoch 189/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 505.3528\n",
      "Epoch 190/500\n",
      "94/94 [==============================] - 0s 385us/sample - loss: 505.2686\n",
      "Epoch 191/500\n",
      "94/94 [==============================] - 0s 399us/sample - loss: 505.1783\n",
      "Epoch 192/500\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 505.3916\n",
      "Epoch 193/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 504.9192\n",
      "Epoch 194/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 505.2330\n",
      "Epoch 195/500\n",
      "94/94 [==============================] - 0s 476us/sample - loss: 504.7763\n",
      "Epoch 196/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 505.1027\n",
      "Epoch 197/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 504.6407\n",
      "Epoch 198/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 504.9736\n",
      "Epoch 199/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 504.5073\n",
      "Epoch 200/500\n",
      "94/94 [==============================] - 0s 456us/sample - loss: 504.8458\n",
      "Epoch 201/500\n",
      "94/94 [==============================] - 0s 450us/sample - loss: 504.3768\n",
      "Epoch 202/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 504.7190\n",
      "Epoch 203/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 504.2480\n",
      "Epoch 204/500\n",
      "94/94 [==============================] - 0s 463us/sample - loss: 504.5935\n",
      "Epoch 205/500\n",
      "94/94 [==============================] - 0s 455us/sample - loss: 504.1218\n",
      "Epoch 206/500\n",
      "94/94 [==============================] - 0s 403us/sample - loss: 504.4690\n",
      "Epoch 207/500\n",
      "94/94 [==============================] - 0s 707us/sample - loss: 503.9974\n",
      "Epoch 208/500\n",
      "94/94 [==============================] - 0s 421us/sample - loss: 504.3462\n",
      "Epoch 209/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 503.8754\n",
      "Epoch 210/500\n",
      "94/94 [==============================] - 0s 506us/sample - loss: 504.2248\n",
      "Epoch 211/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 503.7556\n",
      "Epoch 212/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 504.1046\n",
      "Epoch 213/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 503.6377\n",
      "Epoch 214/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 503.9863\n",
      "Epoch 215/500\n",
      "94/94 [==============================] - 0s 517us/sample - loss: 503.5220\n",
      "Epoch 216/500\n",
      "94/94 [==============================] - 0s 464us/sample - loss: 503.8699\n",
      "Epoch 217/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 503.4082\n",
      "Epoch 218/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 503.7550\n",
      "Epoch 219/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 503.4828\n",
      "Epoch 220/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 503.4139\n",
      "Epoch 221/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 503.2836\n",
      "Epoch 222/500\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 503.4838\n",
      "Epoch 223/500\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 503.1041\n",
      "Epoch 224/500\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 503.3615\n",
      "Epoch 225/500\n",
      "94/94 [==============================] - 0s 500us/sample - loss: 502.9924\n",
      "Epoch 226/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 503.2597\n",
      "Epoch 227/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 502.8859\n",
      "Epoch 228/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 503.1596\n",
      "Epoch 229/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 502.7817\n",
      "Epoch 230/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 503.0601\n",
      "Epoch 231/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 502.6795\n",
      "Epoch 232/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 502.9622\n",
      "Epoch 233/500\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 502.5795\n",
      "Epoch 234/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 502.8650\n",
      "Epoch 235/500\n",
      "94/94 [==============================] - 0s 440us/sample - loss: 502.4819\n",
      "Epoch 236/500\n",
      "94/94 [==============================] - 0s 393us/sample - loss: 502.7691\n",
      "Epoch 237/500\n",
      "94/94 [==============================] - 0s 421us/sample - loss: 502.3856\n",
      "Epoch 238/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 502.6745\n",
      "Epoch 239/500\n",
      "94/94 [==============================] - 0s 401us/sample - loss: 502.2914\n",
      "Epoch 240/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 502.5813\n",
      "Epoch 241/500\n",
      "94/94 [==============================] - 0s 479us/sample - loss: 502.1986\n",
      "Epoch 242/500\n",
      "94/94 [==============================] - 0s 462us/sample - loss: 502.4894\n",
      "Epoch 243/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 502.1083\n",
      "Epoch 244/500\n",
      "94/94 [==============================] - 0s 495us/sample - loss: 502.3990\n",
      "Epoch 245/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 502.0195\n",
      "Epoch 246/500\n",
      "94/94 [==============================] - 0s 440us/sample - loss: 502.3098\n",
      "Epoch 247/500\n",
      "94/94 [==============================] - 0s 501us/sample - loss: 501.9326\n",
      "Epoch 248/500\n",
      "94/94 [==============================] - 0s 461us/sample - loss: 502.2223\n",
      "Epoch 249/500\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 501.8472\n",
      "Epoch 250/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 502.1360\n",
      "Epoch 251/500\n",
      "94/94 [==============================] - 0s 447us/sample - loss: 501.7636\n",
      "Epoch 252/500\n",
      "94/94 [==============================] - 0s 466us/sample - loss: 502.0511\n",
      "Epoch 253/500\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 501.8713\n",
      "Epoch 254/500\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 501.8177\n",
      "Epoch 255/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 501.6432\n",
      "Epoch 256/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 501.8314\n",
      "Epoch 257/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 501.5456\n",
      "Epoch 258/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 501.7467\n",
      "Epoch 259/500\n",
      "94/94 [==============================] - 0s 462us/sample - loss: 501.4643\n",
      "Epoch 260/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 501.6748\n",
      "Epoch 261/500\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 501.3870\n",
      "Epoch 262/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 501.6037\n",
      "Epoch 263/500\n",
      "94/94 [==============================] - 0s 471us/sample - loss: 501.3116\n",
      "Epoch 264/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 501.5335\n",
      "Epoch 265/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 501.2378\n",
      "Epoch 266/500\n",
      "94/94 [==============================] - 0s 503us/sample - loss: 501.4638\n",
      "Epoch 267/500\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 501.1659\n",
      "Epoch 268/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 501.3949\n",
      "Epoch 269/500\n",
      "94/94 [==============================] - 0s 455us/sample - loss: 501.0953\n",
      "Epoch 270/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 501.3272\n",
      "Epoch 271/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 501.0267\n",
      "Epoch 272/500\n",
      "94/94 [==============================] - 0s 467us/sample - loss: 501.2603\n",
      "Epoch 273/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 500.9597\n",
      "Epoch 274/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 501.1564\n",
      "Epoch 275/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 500.5725\n",
      "Epoch 276/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 500.8609\n",
      "Epoch 277/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 500.7949\n",
      "Epoch 278/500\n",
      "94/94 [==============================] - 0s 455us/sample - loss: 500.6980\n",
      "Epoch 279/500\n",
      "94/94 [==============================] - 0s 453us/sample - loss: 500.6282\n",
      "Epoch 280/500\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 500.7394\n",
      "Epoch 281/500\n",
      "94/94 [==============================] - 0s 470us/sample - loss: 500.9217\n",
      "Epoch 282/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 500.5765\n",
      "Epoch 283/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 500.4926\n",
      "Epoch 284/500\n",
      "94/94 [==============================] - 0s 471us/sample - loss: 500.5669\n",
      "Epoch 285/500\n",
      "94/94 [==============================] - 0s 452us/sample - loss: 500.5390\n",
      "Epoch 286/500\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 500.4532\n",
      "Epoch 287/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 500.2530\n",
      "Epoch 288/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 500.3652\n",
      "Epoch 289/500\n",
      "94/94 [==============================] - 0s 401us/sample - loss: 500.4764\n",
      "Epoch 290/500\n",
      "94/94 [==============================] - 0s 399us/sample - loss: 500.6498\n",
      "Epoch 291/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 500.4413\n",
      "Epoch 292/500\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 500.5917\n",
      "Epoch 293/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 500.3875\n",
      "Epoch 294/500\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 500.5001\n",
      "Epoch 295/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 500.0471\n",
      "Epoch 296/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 500.1707\n",
      "Epoch 297/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 500.1206\n",
      "Epoch 298/500\n",
      "94/94 [==============================] - 0s 397us/sample - loss: 500.0543\n",
      "Epoch 299/500\n",
      "94/94 [==============================] - 0s 395us/sample - loss: 500.1694\n",
      "Epoch 300/500\n",
      "94/94 [==============================] - 0s 458us/sample - loss: 500.1682\n",
      "Epoch 301/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 500.3759\n",
      "Epoch 302/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 500.3365\n",
      "Epoch 303/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 500.0989\n",
      "Epoch 304/500\n",
      "94/94 [==============================] - 0s 463us/sample - loss: 499.9774\n",
      "Epoch 305/500\n",
      "94/94 [==============================] - 0s 403us/sample - loss: 499.9122\n",
      "Epoch 306/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 499.8557\n",
      "Epoch 307/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 499.9766\n",
      "Epoch 308/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 500.2070\n",
      "Epoch 309/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 500.0192\n",
      "Epoch 310/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 500.1570\n",
      "Epoch 311/500\n",
      "94/94 [==============================] - 0s 408us/sample - loss: 499.5752\n",
      "Epoch 312/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 499.7771\n",
      "Epoch 313/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 499.5562\n",
      "Epoch 314/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 499.7265\n",
      "Epoch 315/500\n",
      "94/94 [==============================] - 0s 453us/sample - loss: 499.7000\n",
      "Epoch 316/500\n",
      "94/94 [==============================] - 0s 526us/sample - loss: 499.6398\n",
      "Epoch 317/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 499.4435\n",
      "Epoch 318/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 499.6239\n",
      "Epoch 319/500\n",
      "94/94 [==============================] - 0s 524us/sample - loss: 499.6028\n",
      "Epoch 320/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 499.5478\n",
      "Epoch 321/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 499.6700\n",
      "Epoch 322/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 499.9077\n",
      "Epoch 323/500\n",
      "94/94 [==============================] - 0s 505us/sample - loss: 499.3333\n",
      "Epoch 324/500\n",
      "94/94 [==============================] - 0s 450us/sample - loss: 499.4938\n",
      "Epoch 325/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 499.2907\n",
      "Epoch 326/500\n",
      "94/94 [==============================] - 0s 488us/sample - loss: 499.4724\n",
      "Epoch 327/500\n",
      "94/94 [==============================] - 0s 409us/sample - loss: 499.4717\n",
      "Epoch 328/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 499.4112\n",
      "Epoch 329/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 499.1999\n",
      "Epoch 330/500\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 499.3826\n",
      "Epoch 331/500\n",
      "94/94 [==============================] - 0s 456us/sample - loss: 499.3873\n",
      "Epoch 332/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 499.3317\n",
      "Epoch 333/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 499.1218\n",
      "Epoch 334/500\n",
      "94/94 [==============================] - 0s 464us/sample - loss: 499.2935\n",
      "Epoch 335/500\n",
      "94/94 [==============================] - 0s 483us/sample - loss: 499.3035\n",
      "Epoch 336/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 499.3232\n",
      "Epoch 337/500\n",
      "94/94 [==============================] - 0s 492us/sample - loss: 499.2512\n",
      "Epoch 338/500\n",
      "94/94 [==============================] - 0s 416us/sample - loss: 499.2471\n",
      "Epoch 339/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 499.0286\n",
      "Epoch 340/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 498.8781\n",
      "Epoch 341/500\n",
      "94/94 [==============================] - 0s 464us/sample - loss: 498.7307\n",
      "Epoch 342/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 498.6498\n",
      "Epoch 343/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 498.9493\n",
      "Epoch 344/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 498.9315\n",
      "Epoch 345/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 498.8511\n",
      "Epoch 346/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 498.7123\n",
      "Epoch 347/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 498.7865\n",
      "Epoch 348/500\n",
      "94/94 [==============================] - 0s 459us/sample - loss: 499.0473\n",
      "Epoch 349/500\n",
      "94/94 [==============================] - 0s 478us/sample - loss: 498.6813\n",
      "Epoch 350/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 498.4888\n",
      "Epoch 351/500\n",
      "94/94 [==============================] - 0s 421us/sample - loss: 498.3405\n",
      "Epoch 352/500\n",
      "94/94 [==============================] - 0s 651us/sample - loss: 498.5273\n",
      "Epoch 353/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 498.5692\n",
      "Epoch 354/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 498.3544\n",
      "Epoch 355/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 498.3673\n",
      "Epoch 356/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 498.3006\n",
      "Epoch 357/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 498.7225\n",
      "Epoch 358/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 498.4232\n",
      "Epoch 359/500\n",
      "94/94 [==============================] - 0s 481us/sample - loss: 498.3211\n",
      "Epoch 360/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 498.4189\n",
      "Epoch 361/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 498.3860\n",
      "Epoch 362/500\n",
      "94/94 [==============================] - 0s 472us/sample - loss: 498.1665\n",
      "Epoch 363/500\n",
      "94/94 [==============================] - 0s 452us/sample - loss: 498.2744\n",
      "Epoch 364/500\n",
      "94/94 [==============================] - 0s 429us/sample - loss: 498.3119\n",
      "Epoch 365/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 498.1796\n",
      "Epoch 366/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 499.5391\n",
      "Epoch 367/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 501.3326\n",
      "Epoch 368/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 495.8139\n",
      "Epoch 369/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 497.5981\n",
      "Epoch 370/500\n",
      "94/94 [==============================] - 0s 450us/sample - loss: 496.9579\n",
      "Epoch 371/500\n",
      "94/94 [==============================] - 0s 527us/sample - loss: 496.6717\n",
      "Epoch 372/500\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 496.6817\n",
      "Epoch 373/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 496.4120\n",
      "Epoch 374/500\n",
      "94/94 [==============================] - 0s 476us/sample - loss: 496.2639\n",
      "Epoch 375/500\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 496.6760\n",
      "Epoch 376/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 497.3007\n",
      "Epoch 377/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 496.9452\n",
      "Epoch 378/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 497.0989\n",
      "Epoch 379/500\n",
      "94/94 [==============================] - 0s 395us/sample - loss: 497.0289\n",
      "Epoch 380/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 496.6433\n",
      "Epoch 381/500\n",
      "94/94 [==============================] - 0s 471us/sample - loss: 496.9428\n",
      "Epoch 382/500\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 496.3755\n",
      "Epoch 383/500\n",
      "94/94 [==============================] - 0s 424us/sample - loss: 497.0937\n",
      "Epoch 384/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 496.7597\n",
      "Epoch 385/500\n",
      "94/94 [==============================] - 0s 464us/sample - loss: 496.3558\n",
      "Epoch 386/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 495.7633\n",
      "Epoch 387/500\n",
      "94/94 [==============================] - 0s 538us/sample - loss: 496.4847\n",
      "Epoch 388/500\n",
      "94/94 [==============================] - 0s 516us/sample - loss: 495.8928\n",
      "Epoch 389/500\n",
      "94/94 [==============================] - 0s 461us/sample - loss: 496.3541\n",
      "Epoch 390/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 496.7448\n",
      "Epoch 391/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 495.5258\n",
      "Epoch 392/500\n",
      "94/94 [==============================] - 0s 473us/sample - loss: 496.3832\n",
      "Epoch 393/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 495.8386\n",
      "Epoch 394/500\n",
      "94/94 [==============================] - 0s 406us/sample - loss: 495.9515\n",
      "Epoch 395/500\n",
      "94/94 [==============================] - 0s 457us/sample - loss: 496.4750\n",
      "Epoch 396/500\n",
      "94/94 [==============================] - 0s 450us/sample - loss: 495.7958\n",
      "Epoch 397/500\n",
      "94/94 [==============================] - 0s 423us/sample - loss: 496.0174\n",
      "Epoch 398/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 495.9867\n",
      "Epoch 399/500\n",
      "94/94 [==============================] - 0s 487us/sample - loss: 495.6194\n",
      "Epoch 400/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 495.6617\n",
      "Epoch 401/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 496.0410\n",
      "Epoch 402/500\n",
      "94/94 [==============================] - 0s 491us/sample - loss: 495.2458\n",
      "Epoch 403/500\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 494.7616\n",
      "Epoch 404/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 495.5400\n",
      "Epoch 405/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 495.2461\n",
      "Epoch 406/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 495.8403\n",
      "Epoch 407/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 495.1813\n",
      "Epoch 408/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 495.4695\n",
      "Epoch 409/500\n",
      "94/94 [==============================] - 0s 411us/sample - loss: 495.9257\n",
      "Epoch 410/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 494.7221\n",
      "Epoch 411/500\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 496.1406\n",
      "Epoch 412/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 494.9633\n",
      "Epoch 413/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 494.9295\n",
      "Epoch 414/500\n",
      "94/94 [==============================] - 0s 501us/sample - loss: 495.0868\n",
      "Epoch 415/500\n",
      "94/94 [==============================] - 0s 437us/sample - loss: 495.7713\n",
      "Epoch 416/500\n",
      "94/94 [==============================] - 0s 436us/sample - loss: 495.0589\n",
      "Epoch 417/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 494.8370\n",
      "Epoch 418/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 495.6585\n",
      "Epoch 419/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 494.8151\n",
      "Epoch 420/500\n",
      "94/94 [==============================] - 0s 449us/sample - loss: 494.9938\n",
      "Epoch 421/500\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 494.5915\n",
      "Epoch 422/500\n",
      "94/94 [==============================] - 0s 485us/sample - loss: 494.7133\n",
      "Epoch 423/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 495.8220\n",
      "Epoch 424/500\n",
      "94/94 [==============================] - 0s 513us/sample - loss: 494.9081\n",
      "Epoch 425/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 494.4934\n",
      "Epoch 426/500\n",
      "94/94 [==============================] - 0s 439us/sample - loss: 494.7909\n",
      "Epoch 427/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 494.3998\n",
      "Epoch 428/500\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 494.5139\n",
      "Epoch 429/500\n",
      "94/94 [==============================] - 0s 467us/sample - loss: 494.6849\n",
      "Epoch 430/500\n",
      "94/94 [==============================] - 0s 415us/sample - loss: 495.7040\n",
      "Epoch 431/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 494.3247\n",
      "Epoch 432/500\n",
      "94/94 [==============================] - 0s 467us/sample - loss: 494.3010\n",
      "Epoch 433/500\n",
      "94/94 [==============================] - 0s 465us/sample - loss: 494.5537\n",
      "Epoch 434/500\n",
      "94/94 [==============================] - 0s 396us/sample - loss: 494.5028\n",
      "Epoch 435/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 495.4728\n",
      "Epoch 436/500\n",
      "94/94 [==============================] - 0s 516us/sample - loss: 494.5532\n",
      "Epoch 437/500\n",
      "94/94 [==============================] - 0s 460us/sample - loss: 494.3252\n",
      "Epoch 438/500\n",
      "94/94 [==============================] - 0s 435us/sample - loss: 494.2758\n",
      "Epoch 439/500\n",
      "94/94 [==============================] - 0s 440us/sample - loss: 494.2140\n",
      "Epoch 440/500\n",
      "94/94 [==============================] - 0s 430us/sample - loss: 494.2298\n",
      "Epoch 441/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 495.3019\n",
      "Epoch 442/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 494.1354\n",
      "Epoch 443/500\n",
      "94/94 [==============================] - 0s 425us/sample - loss: 494.4107\n",
      "Epoch 444/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 494.3315\n",
      "Epoch 445/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 494.1917\n",
      "Epoch 446/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 495.1431\n",
      "Epoch 447/500\n",
      "94/94 [==============================] - 0s 404us/sample - loss: 494.3267\n",
      "Epoch 448/500\n",
      "94/94 [==============================] - 0s 448us/sample - loss: 494.0671\n",
      "Epoch 449/500\n",
      "94/94 [==============================] - 0s 432us/sample - loss: 494.1636\n",
      "Epoch 450/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 493.7477\n",
      "Epoch 451/500\n",
      "94/94 [==============================] - 0s 501us/sample - loss: 494.0333\n",
      "Epoch 452/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 494.7439\n",
      "Epoch 453/500\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 493.8886\n",
      "Epoch 454/500\n",
      "94/94 [==============================] - 0s 468us/sample - loss: 494.0851\n",
      "Epoch 455/500\n",
      "94/94 [==============================] - 0s 490us/sample - loss: 493.9409\n",
      "Epoch 456/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 494.0134\n",
      "Epoch 457/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 493.8880\n",
      "Epoch 458/500\n",
      "94/94 [==============================] - 0s 484us/sample - loss: 493.9523\n",
      "Epoch 459/500\n",
      "94/94 [==============================] - 0s 443us/sample - loss: 493.8783\n",
      "Epoch 460/500\n",
      "94/94 [==============================] - 0s 502us/sample - loss: 494.0766\n",
      "Epoch 461/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 494.0103\n",
      "Epoch 462/500\n",
      "94/94 [==============================] - 0s 442us/sample - loss: 494.8514\n",
      "Epoch 463/500\n",
      "94/94 [==============================] - 0s 446us/sample - loss: 494.3621\n",
      "Epoch 464/500\n",
      "94/94 [==============================] - 0s 438us/sample - loss: 494.6621\n",
      "Epoch 465/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 494.0520\n",
      "Epoch 466/500\n",
      "94/94 [==============================] - 0s 482us/sample - loss: 495.0891\n",
      "Epoch 467/500\n",
      "94/94 [==============================] - 0s 463us/sample - loss: 494.8971\n",
      "Epoch 468/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 496.0684\n",
      "Epoch 469/500\n",
      "94/94 [==============================] - 0s 487us/sample - loss: 493.9813\n",
      "Epoch 470/500\n",
      "94/94 [==============================] - 0s 476us/sample - loss: 495.1951\n",
      "Epoch 471/500\n",
      "94/94 [==============================] - 0s 417us/sample - loss: 494.4824\n",
      "Epoch 472/500\n",
      "94/94 [==============================] - 0s 477us/sample - loss: 494.6352\n",
      "Epoch 473/500\n",
      "94/94 [==============================] - 0s 504us/sample - loss: 493.5353\n",
      "Epoch 474/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 494.9796\n",
      "Epoch 475/500\n",
      "94/94 [==============================] - 0s 410us/sample - loss: 495.0166\n",
      "Epoch 476/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 495.9543\n",
      "Epoch 477/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 494.2943\n",
      "Epoch 478/500\n",
      "94/94 [==============================] - 0s 420us/sample - loss: 495.4022\n",
      "Epoch 479/500\n",
      "94/94 [==============================] - 0s 434us/sample - loss: 493.5837\n",
      "Epoch 480/500\n",
      "94/94 [==============================] - 0s 422us/sample - loss: 494.9970\n",
      "Epoch 481/500\n",
      "94/94 [==============================] - 0s 444us/sample - loss: 494.7395\n",
      "Epoch 482/500\n",
      "94/94 [==============================] - 0s 445us/sample - loss: 494.7828\n",
      "Epoch 483/500\n",
      "94/94 [==============================] - 0s 412us/sample - loss: 493.9087\n",
      "Epoch 484/500\n",
      "94/94 [==============================] - 0s 431us/sample - loss: 495.1367\n",
      "Epoch 485/500\n",
      "94/94 [==============================] - 0s 485us/sample - loss: 493.6518\n",
      "Epoch 486/500\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 496.0256\n",
      "Epoch 487/500\n",
      "94/94 [==============================] - 0s 419us/sample - loss: 494.9886\n",
      "Epoch 488/500\n",
      "94/94 [==============================] - 0s 540us/sample - loss: 494.7526\n",
      "Epoch 489/500\n",
      "94/94 [==============================] - 0s 426us/sample - loss: 493.9636\n",
      "Epoch 490/500\n",
      "94/94 [==============================] - 0s 433us/sample - loss: 495.2110\n",
      "Epoch 491/500\n",
      "94/94 [==============================] - 0s 506us/sample - loss: 493.5569\n",
      "Epoch 492/500\n",
      "94/94 [==============================] - 0s 428us/sample - loss: 493.6310\n",
      "Epoch 493/500\n",
      "94/94 [==============================] - 0s 407us/sample - loss: 493.8988\n",
      "Epoch 494/500\n",
      "94/94 [==============================] - 0s 441us/sample - loss: 494.0522\n",
      "Epoch 495/500\n",
      "94/94 [==============================] - 0s 533us/sample - loss: 495.8875\n",
      "Epoch 496/500\n",
      "94/94 [==============================] - 0s 454us/sample - loss: 494.6123\n",
      "Epoch 497/500\n",
      "94/94 [==============================] - 0s 427us/sample - loss: 494.7433\n",
      "Epoch 498/500\n",
      "94/94 [==============================] - 0s 414us/sample - loss: 493.4250\n",
      "Epoch 499/500\n",
      "94/94 [==============================] - 0s 418us/sample - loss: 495.0605\n",
      "Epoch 500/500\n",
      "94/94 [==============================] - 0s 413us/sample - loss: 495.0690\n",
      "46/46 [==============================] - 0s 394us/sample - loss: 2066.8452\n",
      "\n",
      "Test mse: 2066.84521484375\n",
      "Test rmse: 45.46256938233639\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_neurons = [8,8]\n",
    "n_epochs = 500\n",
    "batch_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_neurons[0], activation='relu', input_shape=(n_x,)))\n",
    "model.add(Dense(num_neurons[1], activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print('\\nTest mse:', score)\n",
    "print('Test rmse:', math.sqrt(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6608683-815d-4592-be6b-d50ab5cb6a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions:\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Shift train predictions for plotting:\n",
    "Y_train_pred_plot = np.empty_like(dataset)\n",
    "Y_train_pred_plot[:, :] = np.nan\n",
    "Y_train_pred_plot[(n_x - 1):(len(Y_train_pred) + n_x - 1), :] = Y_train_pred\n",
    "# ^ Note: great care needed to avoid off-by one!\n",
    "\n",
    "# Shift test predictions for plotting:\n",
    "Y_test_pred_plot = np.empty_like(dataset)\n",
    "Y_test_pred_plot[:, :] = np.nan\n",
    "Y_test_pred_plot[(len(Y_train_pred) + (n_x * 2) - 1):(len(dataset) - 1), :] = Y_test_pred\n",
    "# ^ Note: great care needed to avoid off-by one!\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(dataset,label='Original Data')\n",
    "plt.plot(Y_train_pred_plot,label='Y_train_pred')\n",
    "plt.plot(Y_test_pred_plot,label='Y_test_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
